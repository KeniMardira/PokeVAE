{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from tqdm import tnrange\n",
    "import scipy.ndimage\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "import imageio\n",
    "\n",
    "\n",
    "RESIZE = 128\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pokemon Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pokelist = os.listdir(\"./Pokemon/\")\n",
    "with open(\"./PokeList\", 'w') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(pokelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader class that works with VCTK datasets. Init require the path to a folder where voice_data are stored.\n",
    "class PokeSet(Utils.Dataset): # Main dataset class for dataloader\n",
    "    def __init__(self, path): # takes two input, the input and output Tensors\n",
    "        self.path = path\n",
    "        self.pokelist = pd.read_csv(\"PokeList\",header=None)\n",
    "\n",
    "    \n",
    "    def __len__(self): # must be written for dataset module\n",
    "        return len(os.listdir(self.path))\n",
    "    \n",
    "    def __getitem__(self,index): # must be written for dataset module\n",
    "        pokemon = mpimg.imread(self.path + self.pokelist[index][0])\n",
    "        pokemon = cv2.resize(pokemon, (RESIZE,RESIZE))\n",
    "        pokemon = (pokemon - np.min(pokemon))/np.max(pokemon - np.min(pokemon))\n",
    "        return pokemon\n",
    "    \n",
    "pokeSet = PokeSet(\"./Pokemon/\")\n",
    "pokeLoader = Utils.DataLoader(dataset = pokeSet, shuffle = True, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(pokeLoader):\n",
    "    if i in range(10):\n",
    "        plt.imshow(data[0,:,:,:].squeeze().numpy())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, latent_dim=256):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #encoder\n",
    "        self.conv_e1 = nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn_e1 = nn.BatchNorm2d(32)\n",
    "        self.conv_e2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn_e2 = nn.BatchNorm2d(64)\n",
    "        self.conv_e3 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn_e3 = nn.BatchNorm2d(128)\n",
    "        self.conv_e4 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn_e4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.fc_mean = nn.Linear(256*RESIZE//16*RESIZE//16, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(256*RESIZE//16*RESIZE//16, latent_dim)\n",
    "        \n",
    "        #decoder\n",
    "        self.fc_d = nn.Linear(latent_dim, 256*RESIZE//16*RESIZE//16)\n",
    "        \n",
    "        self.up = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        self.conv_d1 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_d1 = nn.BatchNorm2d(128)\n",
    "        self.conv_d2 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_d2 = nn.BatchNorm2d(64)\n",
    "        self.conv_d3 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_d3 = nn.BatchNorm2d(32)\n",
    "        self.conv_d4 = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        ''' encoder: q(z|x)\n",
    "            input: x, output: mean, logvar\n",
    "        '''\n",
    "        x = F.leaky_relu(self.bn_e1(self.conv_e1(x)))\n",
    "        x = F.leaky_relu(self.bn_e2(self.conv_e2(x)))\n",
    "        x = F.leaky_relu(self.bn_e3(self.conv_e3(x)))\n",
    "        x = F.leaky_relu(self.bn_e4(self.conv_e4(x)))\n",
    "        x = x.view(-1, x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        z_mean = self.fc_mean(x)\n",
    "        z_logvar = self.fc_logvar(x)\n",
    "        return z_mean, z_logvar\n",
    "    \n",
    "    def latent(self, z_mu, z_logvar):\n",
    "        ''' \n",
    "            encoder: z = mu + sd * e\n",
    "            input: mean, logvar. output: z\n",
    "        '''\n",
    "        sd = torch.exp(z_logvar * 0.5)\n",
    "        e = Variable(torch.randn(sd.size())).cuda()\n",
    "        z = e.mul(sd).add_(z_mu)\n",
    "        return z \n",
    "    \n",
    "    def decoder(self, z):\n",
    "        '''\n",
    "            decoder: p(x|z)\n",
    "            input: z. output: x\n",
    "        '''\n",
    "        x = self.fc_d(z)\n",
    "        x = x.view(-1, 256, RESIZE//16, RESIZE//16)\n",
    "        x = F.leaky_relu(self.bn_d1(self.conv_d1(self.up(x))))\n",
    "        x = F.leaky_relu(self.bn_d2(self.conv_d2(self.up(x))))\n",
    "        x = F.leaky_relu(self.bn_d3(self.conv_d3(self.up(x))))\n",
    "        x = F.sigmoid(self.conv_d4(self.up(x)))\n",
    "        return x.view(-1,3,RESIZE,RESIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_mean, z_logvar = self.encoder(x)\n",
    "        z = self.latent(z_mean, z_logvar)\n",
    "        x_out = self.decoder(z)\n",
    "        return x_out, z_mean, z_logvar\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Function\n",
    "\n",
    "$$ 2+2 = 4 - 1 = 3 , Quikmafz$$\n",
    "\n",
    "## $$l_i(\\theta, \\phi) = E_{z\\sim q_\\theta(z\\vert x_i)}[\\log p_\\phi(x_i\\vert z)] - KL(q_\\theta(z\\vert x_i) \\vert\\vert p(z))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#Define Criterion\n",
    "\n",
    "def criterion(x_out, target, z_mean, z_logvar, alpha = 1, beta = 0.5):\n",
    "    bce = F.mse_loss(x_out, target, size_average=False) #Use MSE loss for images\n",
    "    kl = -0.5 * torch.sum(1 + z_logvar - (z_mean**2) - torch.exp(z_logvar)) #Analytical KL Divergence - Assumes p(z) is Gaussian Distribution\n",
    "    loss = ((alpha * bce) + (beta * kl)) / x_out.size(0)    \n",
    "    return loss, bce, kl\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filename):\n",
    "    '''Loading function for the model before and during training\n",
    "    From a checkpoint file, it loads and returns all necessary data (mode, optimiser, epoch number, losses)\n",
    "    input: filename -> The name of the checkpoint file to be opened (.pth or .pt)\n",
    "    output: net -> The saved model, including weights and biases\n",
    "    output: epoch -> The epoch number at which the training was saved\n",
    "    output: loss_save -> An array of all the saved batch losses during training\n",
    "    output: optimizer -> The current state of the optimiser with its updated learning rates from training'''\n",
    "    \n",
    "    net = Net().cuda() # Initialize model  \n",
    "    checkpoint = torch.load(filename) # load checkpoint data\n",
    "    net.load_state_dict(checkpoint['state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    losses = checkpoint['losses']\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=PATIENCE, factor=SCHFACTOR, cooldown=CD, threshold=1e-2)\n",
    "    # scheduler.best = checkpoint['best_loss']\n",
    "    # scheduler.num_bad_epochs = checkpoint['bad_epoch']\n",
    "    \n",
    "    print(\"Loaded checkpoint: \" + filename)\n",
    "    return net, epoch, losses, optimizer#, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pokePlot(images, vae, ROW, COL):\n",
    "    f, axarr = plt.subplots(ROW,COL, figsize=(15,ROW*4))\n",
    "    for row in range(ROW//2):\n",
    "        for col in range(COL):\n",
    "            image = images[col+(COL*row),:,:,:].unsqueeze(0)\n",
    "            axarr[2*row,col].imshow(image.squeeze().numpy())\n",
    "            image = image.permute(0,3,1,2)\n",
    "            x_out, z_mean, z_logvar = vae(Variable(image.float()).cuda())\n",
    "            x_out = x_out.permute(0,2,3,1)\n",
    "            axarr[2*row+1,col].imshow(x_out.data.cpu().squeeze().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "label = \"POKEVAE\"\n",
    "row = 4\n",
    "col = 4\n",
    "\n",
    "def train(model,optimizer,dataloader, epoch, max_epochs=5000):\n",
    "    losses = []\n",
    "    bces = []\n",
    "    kls = []\n",
    "    for _ in range(max_epochs):\n",
    "        epoch += 1\n",
    "        for images in dataloader:\n",
    "            image_in = images.permute(0,3,1,2)\n",
    "            x_in = Variable(image_in.float()).cuda()\n",
    "            optimizer.zero_grad()\n",
    "            x_out, z_mu, z_logvar = model(x_in)\n",
    "            loss, bce, kl = criterion(x_out,x_in,z_mu,z_logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.data[0])\n",
    "            bces.append(bce.data[0])\n",
    "            kls.append(kl.data[0])\n",
    "            \n",
    "            if epoch % 10 == 0 and epoch != 0:\n",
    "                save_file = label + \"_epoch_{:06d}\".format(epoch) + '.pth'\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                    'losses' : losses\n",
    "                }, \"checkpoints/\" + save_file)\n",
    "                \n",
    "        clear_output(wait=True)\n",
    "        pokePlot(images, net, row, col)\n",
    "        print(epoch, 'Loss: {:3f}'.format(loss.data[0]))\n",
    "        \n",
    "    return losses, bces, kls\n",
    " \n",
    "net, epoch, losses, optimizer = load_checkpoint(\"./checkpoints/POKEVAE_epoch_000680.pth\")\n",
    "train_losses, bces, kls = train(net,optimizer,pokeLoader, epoch)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_losses)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(bces)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(kls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(pokeLoader)\n",
    "\n",
    "# image = dataiter.next()\n",
    "\n",
    "pokemon = mpimg.imread(\"./Pokemon/electrode.jpg\")\n",
    "pokemon = cv2.resize(pokemon, (RESIZE,RESIZE))\n",
    "pokemon = (pokemon - np.min(pokemon))/np.max(pokemon - np.min(pokemon))\n",
    "image = torch.from_numpy(pokemon).unsqueeze(0)\n",
    "\n",
    "image = image[0,:,:,:].unsqueeze(0)\n",
    "plt.imshow((image.squeeze().numpy()))\n",
    "plt.show()\n",
    "image = image.permute(0,3,1,2)\n",
    "x_out, z_mean, z_logvar = net(Variable(image.float()).cuda())\n",
    "x_out = x_out.permute(0,2,3,1)\n",
    "plt.imshow(x_out.data.cpu().squeeze().numpy())\n",
    "plt.show()\n",
    "z = net.latent(z_mean, z_logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep(image, dim, min_range, max_range, step):\n",
    "#     plt.imshow((image.squeeze().numpy()))\n",
    "#     plt.show()\n",
    "    image = image.permute(0,3,1,2)\n",
    "    z_mean, z_logvar = net.encoder(Variable(image.float()).cuda())\n",
    "    z = net.latent(z_mean,z_logvar)\n",
    "    for i, sw in enumerate(range(min_range, max_range, step)):\n",
    "        z[0][dim] = sw/10\n",
    "        x_out = net.decoder(z)\n",
    "        x_out = x_out.permute(0,2,3,1)\n",
    "        im = (np.floor(x_out.data.cpu().squeeze().numpy() * 255)).astype(np.uint8)\n",
    "        plt.imsave(\"./sweep/\" + str(dim) + \"/\" + \"{0:03d}\".format(i) + \".png\", im)\n",
    "    generate_animation(\"./sweep/\" + str(dim) + \"/\", dim, (max_range - min_range)//step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_animation(path, dim, num):\n",
    "    images = []\n",
    "    for e in range(num):\n",
    "        img_name = path + \"{0:03d}\".format(e) + '.png'\n",
    "        images.append(mpimg.imread(img_name))\n",
    "    imageio.mimsave(\"./sweep/gif/\" + 'dim' + str(dim) + '_generate_animation.gif', images, fps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.permute(0,2,3,1)\n",
    "for i in range(256):\n",
    "    os.system(\"mkdir ./sweep/\"+str(i))\n",
    "    sweep(image, i, -300, 300, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test data encodings on the latent space\n",
    "def visualize_encoder(model,dataloader):\n",
    "    z_means_x, z_means_y, all_labels = [], [], []\n",
    "    \n",
    "    for images in iter(dataloader):\n",
    "        images = images.permute(0,3,1,2)\n",
    "        z_means,_ = model.encoder(Variable(images.float()))\n",
    "        z_means_x = np.append(z_means_x,z_means[:,0].data.numpy())\n",
    "        z_means_y = np.append(z_means_y,z_means[:,1].data.numpy())\n",
    "#         all_labels = np.append(all_labels,labels.numpy())\n",
    "        \n",
    "    plt.figure(figsize=(6.5,5))\n",
    "    plt.scatter(z_means_x,z_means_y,cmap='inferno')\n",
    "    plt.show()\n",
    "\n",
    "visualize_encoder(net,pokeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize moving average of losses\n",
    "def visualize_losses_moving_average(losses,window=50,boundary='valid'):\n",
    "    mav_losses = np.convolve(losses,np.ones(window)/window,boundary)\n",
    "    corrected_mav_losses = np.append(np.full(window-1,np.nan),mav_losses)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(losses)\n",
    "    plt.plot(corrected_mav_losses)\n",
    "    plt.ylim(ylim)\n",
    "    plt.show()\n",
    "\n",
    "visualize_losses_moving_average(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, _ = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs = Variable(inputs)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        x_out, z_mean, z_logvar = net(inputs)\n",
    "        loss = criterion(x_out, inputs, z_mean, z_logvar)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "#Predict with network\n",
    "outputs, _, _ = net(Variable(images))\n",
    "\n",
    "# _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "#                               for j in range(4)))\n",
    "\n",
    "\n",
    "imshow(torchvision.utils.make_grid(outputs.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test network accuracy\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs, _, _ = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from scipy.stats import norm\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid as make_image_grid\n",
    "from tqdm import tnrange\n",
    "\n",
    "torch.manual_seed(2017) # reproducability\n",
    "sns.set_style('dark')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self,latent_dim=20,hidden_dim=500):\n",
    "        super(VAE,self).__init__()\n",
    "        self.fc_e = nn.Linear(784,hidden_dim)\n",
    "        self.fc_mean = nn.Linear(hidden_dim,latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim,latent_dim)\n",
    "        self.fc_d1 = nn.Linear(latent_dim,hidden_dim)\n",
    "        self.fc_d2 = nn.Linear(hidden_dim,784)\n",
    "            \n",
    "    def encoder(self,x_in):\n",
    "        x = F.relu(self.fc_e(x_in.view(-1,784)))\n",
    "        mean = self.fc_mean(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def decoder(self,z):\n",
    "        z = F.relu(self.fc_d1(z))\n",
    "        x_out = F.sigmoid(self.fc_d2(z))\n",
    "        return x_out.view(-1,1,28,28)\n",
    "    \n",
    "    def sample_normal(self,mean,logvar):\n",
    "        # Using torch.normal(means,sds) returns a stochastic tensor which we cannot backpropogate through.\n",
    "        # Instead we utilize the 'reparameterization trick'.\n",
    "        # http://stats.stackexchange.com/a/205336\n",
    "        # http://dpkingma.com/wordpress/wp-content/uploads/2015/12/talk_nips_workshop_2015.pdf\n",
    "        sd = torch.exp(logvar*0.5)\n",
    "        e = Variable(torch.randn(sd.size())) # Sample from standard normal\n",
    "        z = e.mul(sd).add_(mean)\n",
    "        return z\n",
    "    \n",
    "    def forward(self,x_in):\n",
    "        z_mean, z_logvar = self.encoder(x_in)\n",
    "        z = self.sample_normal(z_mean,z_logvar)\n",
    "        x_out = self.decoder(z)\n",
    "        return x_out, z_mean, z_logvar\n",
    "\n",
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def criterion(x_out,x_in,z_mu,z_logvar):\n",
    "    bce_loss = F.binary_cross_entropy(x_out,x_in,size_average=False)\n",
    "    kld_loss = -0.5 * torch.sum(1 + z_logvar - (z_mu ** 2) - torch.exp(z_logvar))\n",
    "    loss = (bce_loss + kld_loss) / x_out.size(0) # normalize by batch size\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "trainloader = DataLoader(\n",
    "    MNIST(root='./MNIST',train=True,download=True,transform=transforms.ToTensor()),\n",
    "    batch_size=128,shuffle=True)\n",
    "testloader = DataLoader(\n",
    "    MNIST(root='./MNIST',train=False,download=True,transform=transforms.ToTensor()),\n",
    "    batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(model,optimizer,dataloader,epochs=15):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for images,_ in dataloader:\n",
    "            x_in = Variable(images)\n",
    "            optimizer.zero_grad()\n",
    "            x_out, z_mu, z_logvar = model(x_in)\n",
    "            loss = criterion(x_out,x_in,z_mu,z_logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.data[0])\n",
    "        print('Loss: {:4f}'.format(loss.data[0]))\n",
    "    return losses\n",
    "\n",
    "train_losses = train(model,optimizer,trainloader)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_source]",
   "language": "python",
   "name": "conda-env-pytorch_source-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
